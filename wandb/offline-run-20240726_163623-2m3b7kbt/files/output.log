Using device: cuda:3
Epoch 1/50
  0%|                                                                                                 | 0/656 [00:00<?, ?it/s]/home_ext/whm_ext/hcq/7/flood_unet/datasets/dataloader.py:11: RuntimeWarning: divide by zero encountered in divide
  ratio_image = np.clip(np.nan_to_num(vh_image / vv_image, 0), 0, 1)
/home_ext/whm_ext/hcq/7/flood_unet/datasets/dataloader.py:11: RuntimeWarning: divide by zero encountered in divide
  ratio_image = np.clip(np.nan_to_num(vh_image / vv_image, 0), 0, 1)
/home_ext/whm_ext/hcq/7/flood_unet/datasets/dataloader.py:11: RuntimeWarning: divide by zero encountered in divide
  ratio_image = np.clip(np.nan_to_num(vh_image / vv_image, 0), 0, 1)
/home_ext/whm_ext/hcq/7/flood_unet/datasets/dataloader.py:11: RuntimeWarning: invalid value encountered in divide
  ratio_image = np.clip(np.nan_to_num(vh_image / vv_image, 0), 0, 1)
/home_ext/whm_ext/hcq/7/flood_unet/datasets/dataloader.py:11: RuntimeWarning: invalid value encountered in divide
  ratio_image = np.clip(np.nan_to_num(vh_image / vv_image, 0), 0, 1)
/home_ext/whm_ext/hcq/7/flood_unet/datasets/dataloader.py:11: RuntimeWarning: divide by zero encountered in divide
  ratio_image = np.clip(np.nan_to_num(vh_image / vv_image, 0), 0, 1)
/home_ext/whm_ext/hcq/7/flood_unet/datasets/dataloader.py:11: RuntimeWarning: invalid value encountered in divide
  ratio_image = np.clip(np.nan_to_num(vh_image / vv_image, 0), 0, 1)
/home_ext/whm_ext/hcq/7/flood_unet/datasets/dataloader.py:11: RuntimeWarning: invalid value encountered in divide
  ratio_image = np.clip(np.nan_to_num(vh_image / vv_image, 0), 0, 1)
/home_ext/whm_ext/miniconda3/envs/camera/lib/python3.8/site-packages/torch/nn/functional.py:756: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
  0%|                                                                                                 | 0/656 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "train.py", line 212, in <module>
    train(net, args)
  File "train.py", line 72, in train
    output = net(t1_img, t2_img)
  File "/home_ext/whm_ext/miniconda3/envs/camera/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home_ext/whm_ext/hcq/7/flood_unet/network/model.py", line 76, in forward
    s1_feature = self.s1_stream(t1_img)
  File "/home_ext/whm_ext/miniconda3/envs/camera/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home_ext/whm_ext/hcq/7/flood_unet/network/model.py", line 147, in forward
    out = layer(inputs[-1])
  File "/home_ext/whm_ext/miniconda3/envs/camera/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home_ext/whm_ext/hcq/7/flood_unet/network/model.py", line 205, in forward
    x = self.mpconv(x)
  File "/home_ext/whm_ext/miniconda3/envs/camera/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home_ext/whm_ext/miniconda3/envs/camera/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home_ext/whm_ext/miniconda3/envs/camera/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home_ext/whm_ext/hcq/7/flood_unet/network/model.py", line 178, in forward
    x = self.conv(x)
  File "/home_ext/whm_ext/miniconda3/envs/camera/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home_ext/whm_ext/miniconda3/envs/camera/lib/python3.8/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home_ext/whm_ext/miniconda3/envs/camera/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home_ext/whm_ext/miniconda3/envs/camera/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 443, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home_ext/whm_ext/miniconda3/envs/camera/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 439, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Unable to find a valid cuDNN algorithm to run convolution